{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U - Net\n",
    "\n",
    "@author: claudio1975\n",
    "\n",
    "Picked - up model from https://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification and added batch normalization.\n",
    "References for U-net CNN architecture from: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "# Split dataframe into train/validation\n",
    "ids_train, ids_valid,x_train, x_valid, y_train, y_valid, depth_train, depth_test = train_test_split(\n",
    "    dataframe_depth,\n",
    "    train_x_resized.values,\n",
    "    np.array(train_x_resized.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_x_resized.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model\n",
    "def build_model(input_layer, start_neurons):\n",
    "    # 128 -> 64\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    batch1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 64 -> 32\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    batch2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    # 32 -> 16\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\",padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\",padding=\"same\")(conv3)\n",
    "    batch3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    # 16 -> 8\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\",padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\",padding=\"same\")(conv4)\n",
    "    batch4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\",padding=\"same\")(pool4)\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\",padding=\"same\")(convm)\n",
    "\n",
    "    # 8 -> 16\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2),padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.5)(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\",padding=\"same\")(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\",padding=\"same\")(uconv4)\n",
    "\n",
    "    # 16 -> 32\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2),padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(0.5)(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\",padding=\"same\")(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\",padding=\"same\")(uconv3)\n",
    "\n",
    "    # 32 -> 64\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2),padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.5)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\",padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\",padding=\"same\")(uconv2)\n",
    "\n",
    "    # 64 -> 128\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2),padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.5/2)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\",padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\",padding=\"same\")(uconv1)\n",
    "\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./keras.model\", save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "\n",
    "model = load_model(\"./keras.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\n",
    "preds_valid = np.array([downsample(x) for x in preds_valid])\n",
    "y_valid_ori = np.array([train_x_resized.loc[idx].masks for idx in ids_valid])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
